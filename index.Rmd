---
title: "Machine Learning"
author: "Hinrichs"
date: "December 21, 2015"
output: html_document
---

```{r ref.label="setup", echo=FALSE, warning=FALSE}
```

## Executive Summary

The goal of this project is to predict whether a participant performed an exercise correctly, or if not, which common flaw was detected.

The data comes from <http://groupware.les.inf.puc-rio.br/har>. It is kindly provided under the Creative Commons license (CC BY-SA). The original study is from Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. [Qualitative Activity Recognition of Weight Lifting Exercises](http://groupware.les.inf.puc-rio.br/work.jsf?p1=11201). Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013.

For the course project, the data has been split into separate training and test sets at <https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv> and <https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv>. The classe column has been removed from the testing set. We are to build a model from the training set data and use it to predict the missing column in the test set.


## Exploratory Data Analysis

First load the data. The function to load the data can be found in the appendix.

```{r}
trainRaw <- getTrainData()
testRaw <- getTestData()
```

The data consists of a number of observations from four sensors positioned on the participants, and a classe variable describing the quality of the exercise. The exercise chosen for the study is the Unilateral Dumbbell Biceps Curl. Each repetition by the study participants was classified as

- A. Correct
- B. Throwing elbows to the front
- C. Lifting the dumbbell only halfway
- D. Lowering the dumbbell only halfway
- E. Throwing the hips to the front.

Each sensor provides three-axis data for each of gyros, accel, magnet (nine readings total). The dataset also contains four Euler angle values derived from the nine axis readings.

The dataset consists of two types of rows, time snapshots rows, and summary rows. The snapshot rows have the above values for a sliding window during the exercise. The summary rows have summary data (mean, variance, min, max, etc.) for a single repetition of the exercise. The details can be found in the above referenced paper. The key take-away is that the different rows should not be mixed in our analysis. The different row types can be distinguished with the "new_window" variable. 

While it would seem better to focus on the summary data as the original reserchers did, we are provided a test set that consists only of snapshot type rows. So we are going to discard the summary rows in the training dataset, and only deal with the snapshot type rows.


```{r}
goodRows <- trainRaw$new_window == "no"
```

Many of the columns were used only for the summary rows. These columns have blanks or NA for all the non-summary rows. Let's remove them. There are also few columns at the head of the dataset that are used to describe the sample conditions (time, participant, etc.). Let's remove those as well, and generate cooked versions of the test and train sets.


```{r}
goodColumns <- colSums(is.na(trainRaw)) == 0
goodColumns <- goodColumns & ! colnames(trainRaw) %in% c("X", "user_name", "raw_timestamp_part_1", "cvtd_timestamp", "new_window")
classeCol = which(colnames(trainRaw)=="classe")
trainCooked = trainRaw[goodRows,goodColumns]
testCooked = testRaw[,goodColumns[-classeCol]]
```

The raw training data has `r nrow(trainRaw)` rows and `r ncol(trainRaw)` columns. After cooking, the training data has `r nrow(trainCooked)` rows and `r ncol(trainCooked)` columns. The test data has been reduced to `r ncol(testCooked)` columns.


```{r ref.label="trainAndTest", echo=FALSE, warning=FALSE}
```


I experimented with several models. The appendix has a function TrainAndTest that handles the repetitive steps in the experimentation. The TrainAndTest function generates a training set of the specified size, optionally does center and scale pre-processing, then runs the train function with a specified method, predictors and train control. It then generates a confusion matrix using the test set held out from the training sets, and an answer vector using the Coursera provided test set.

Each data row has the raw xyz axis readings as well as computed Euler angle values. It proved interesting to invesitgate models with all of the variables, or with just the axis or angle values separately.

```{r}
xyzVars = c(7:15, 20:28, 33:41, 46:54)
eulerVars = setdiff( c(1:54), xyzVars )
```

As one would expect, the size of the training set and the number of predictors strongly influence how long the training function runs. Obviously, the ability to make good prediction is the primary goal. Beyond that, speed is also a consideration for the final model.

### Final Model

```{r warning=FALSE, cache=TRUE}
trainControl <- trainControl(method="cv", number=5)
TrainAndTest(0.5, method="gbm", predictors=eulerVars, trainControl=trainControl)
finalAnswer <- answer
```

For the final model I choose the **`r result$method`** method with the formula "classe ~ `r result$predictors`". 

Train control was set to `r result$trainControl$number`-fold cross validation. **`r sprintf( "%2.0f", 100.0*result$p )`%** of the data was used for training. 

The result is **`r sprintf( "%1.4f", result$confusion$overall["Accuracy"])`** accuracy with and expected out of sample error of **`r sprintf( "%1.4f", 1.0-result$confusion$overall["Accuracy"])`**.

The training ran in `r result$time["user.self"]` seconds.

The full confusion matrix:

```{r echo=FALSE}
result$confusion
#confusion
```

## Results

Final Answer: `r finalAnswer`


#Appendix
Good Columns (full list of columns retained during the data cleaning phase):
```{r}
colnames(trainRaw)[goodColumns] 
```

Not Good Columns (full list of columns discarded during the data cleaning phase):
```{r}
colnames(trainRaw)[!goodColumns]
```


```{r}

```

The TrainAndTest function:

```{r trainAndTest }
printIt <- function( x = result ) {
    sprintf( "p=%0.2f, m=%5s, time=%3.0fs, acc=%0.2f, pp=%i, tc=%s-%i, predictors=%s\n"
                 , x$p, x$method, x$time["user.self"], x$confusion["Accuracy"]
                 , 0+x$pp, x$trainControl$method, x$trainControl$number, x$predictors)
}


TrainAndTest <- function( p, method="rf", pp=FALSE, predictors="num_window", trainControl=NULL ) {
    set.seed(20151222)  #Set random seed to ensure consistent results.
    t0 <- proc.time();  #start timing the operation.
        #Create training and test sets. The input p determines the size of the training set.        
    inTrain <- createDataPartition(trainCooked$classe, p=p, list=FALSE )
    train1 <- trainCooked[inTrain,]
    test1 <- testCooked
    test2 <- trainCooked[-inTrain,]
        #Preprocess the data if requested by the pp input value
    if( pp ) {
        preProc = preProcess( train1, methods=c("center","scale"))
        train1 <<- predict(preProc,train1)
        test1 <<- predict(preProc,test1)
        test2 <<- predict(preProc,test2)
    }
        #Build up a formula of the form "class ~ predictors"
    if( class(predictors) == "integer" ||  class(predictors) == "numeric") {
        predictors = colnames(train1)[predictors]
    }
    if( length(predictors) == 1 && predictors == ".") {
        #Nothing happens here. Use the dot as-is
    } else {
        predictors <- paste0( predictors, " + ", collapse="" )
        predictors <- substr(predictors,1,nchar(predictors)-3)
    }
    formula <- as.formula(paste0("classe~", predictors))
    if( is.null(trainControl) ) {   #provide a default trainControl if not specified in the input.
        trainControl <- trainControl(allowParallel = TRUE, verboseIter=FALSE)
    }
        #gbm is very noisy and need verbose=FALSE. Some other methods choke with this setting.
    if( method == "gbm" ) {
        fit1 <- train( formula, method=method, data=train1, trControl = trainControl, verbose=FALSE )
    } else {
        fit1 <- train( formula, method=method, data=train1, trControl = trainControl )
    }
        #Generate predicted result for the final test 
    predict1 <- predict(fit1, testCooked)
        #Test model against the test set, and generate the confusion matrix.        
    predict <- predict(fit1, test2)
    confusion <- confusionMatrix(predict, test2$classe)
    t1 <- proc.time();
        #Collect information about this run and put it in the global result variable.
    result <<- list( p = p, method=method, time = t1-t0, confusion=confusion, pp=pp, trainControl=trainControl, predictors=predictors)
        #also populate the answer vector in case this run is selected as the final model
    answer <<- predict1
    #write( printIt(result), "results.txt", append=TRUE)
    #printIt( result )
    #print(answer)
    #write( paste(answer, sep=" "), "results.txt", append=TRUE)
}
```


Function to create separate files to submit for assigment.

```{r}
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

#pml_write_files(finalAnswers)

```


The setup up chunk. This loads the caret library and the libraries needed by caret. Data files are downloaded from the internet and stored on the local hard drive. The getData functions load those files into memory.

```{r setup}
#setup
library(parallel)
library(survival)
library(splines)
library(plyr)
library(lattice)
library(ggplot2)
suppressMessages(library(gbm))
suppressMessages(library(randomForest))
suppressMessages(library(caret))
#library(stats)
#library(grid)
#library(gridExtra)

trainFile <- "data/train.csv"
testFile <- "data/test.csv"

getData<-function() {
        ##Data files are stored in the "data" directory off of getwd()
        ##Intermediate forms of the data are kept for inspection and for caching
    url<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
    if( ! dir.exists("data") ) {
        dir.create("data")
    }
    if( ! file.exists(trainFile) ) {          ##Skip the prep steps if the cooked subset is ready.
        print("Downloading train file" )
        download.file(url,trainFile)
    }
    url<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
    if( ! file.exists(testFile) ) {          ##Skip the prep steps if the cooked subset is ready.
        print("Downloading train file" )
        download.file(url,testFile)
    }
}

getTrainData<-function() {
    read.csv(trainFile, na.strings = c("NA", ""))
}

getTestData<-function() {
    read.csv(testFile, na.strings = c("NA", ""))
}


```


## Experimenting with models.

The main report only talks about the final model. However getting to the final model was fun. Here are some highlights of the journey. There is nothing in this section that is necessary for the assignment. Feel free to
skip it. 

The following is output from a function very similar to the TrainAndTest function posted above. Sorry, I do not have
the time to put this up in true Rmd fashion, running the code in-line. This is cut and paste from logs that
were generated while I was experimenting. I am showing it as r comments, as that is the only way I know to get
monospaced fonts.

I started with five methods, gbm, rf, lda, rpart, and treebag. First I wanted to get a sense of training time. I started with a very small training set, the increased the size and noted an approximately linear increase in
time. Also, as expected accuracy improved with the larger training set. lda and rpart are the fasted, but the
accuracy was poor. The other three were similar in speed and accuracy.


```{r}
#p=0.01, m=  gbm, time=  3s, acc=0.74, pp=0, tc=cv-2, ans=CACAAEDBAABCBABAEEBB predictors=.
#p=0.01, m=   rf, time=  3s, acc=0.72, pp=0, tc=cv-2, ans=CACAAEDBAACCBABAAAAB predictors=.
#p=0.01, m=  lda, time=  1s, acc=0.63, pp=0, tc=cv-2, ans=EABCAEDDAADABABAAEAB predictors=.
#p=0.01, m=rpart, time=  1s, acc=0.43, pp=0, tc=cv-2, ans=CACAACCAAACCCACAAAAC predictors=.
#p=0.01, m=treebag, time=  4s, acc=0.69, pp=0, tc=cv-2, ans=DACAACDBAAACBABAEAAB predictors=.

#p=0.04, m=  gbm, time=  6s, acc=0.90, pp=0, tc=cv-2, ans=CABAAEDBAAACBAEEABAB predictors=.
#p=0.04, m=   rf, time=  9s, acc=0.90, pp=0, tc=cv-2, ans=CABAAEDDAACCBAEEADBB predictors=.
#p=0.04, m=  lda, time=  1s, acc=0.68, pp=0, tc=cv-2, ans=CABAACDDAADAEABAADBB predictors=.
#p=0.04, m=rpart, time=  1s, acc=0.54, pp=0, tc=cv-2, ans=CAEAAEDAAAEEEAEAAAAE predictors=.
#p=0.04, m=treebag, time=  8s, acc=0.89, pp=0, tc=cv-2, ans=CABAAEDDAACCBAEEAABB predictors=.

#p=0.10, m=  gbm, time= 14s, acc=0.95, pp=0, tc=cv-2, ans=CABAAEDBAABCBAEEABBB predictors=.
#p=0.10, m=   rf, time= 20s, acc=0.96, pp=0, tc=cv-2, ans=BABAAEDDAABCBAEEAABB predictors=.
#p=0.10, m=  lda, time=  1s, acc=0.70, pp=0, tc=cv-2, ans=BABCACDDAADABABAABBB predictors=.
#p=0.10, m=rpart, time=  2s, acc=0.54, pp=0, tc=cv-2, ans=ACCAACCCAACCCACCAAAC predictors=.
#p=0.10, m=treebag, time= 18s, acc=0.95, pp=0, tc=cv-2, ans=BABAABDDAABCBAEEABBB predictors=.
```

Next I wanted to trim the predictor list. As I mentioned in the body of the report, the axis data
and the angle data are related, the angle data is a transformation of the axis data. So I wanted
to try the two sets separately. Everything was faster, about half the time using half the variables.
Accuracy for just the Euler variable was slightly better than for the models using all of the
variables. Faster and more accurate made it an easy choice going forward.

```{r}
#p=0.10, m=  gbm, time= 10s, acc=0.87, pp=0, tc=cv-2, ans=CABAABDBAAACBAEEABBB predictors=xyz
#p=0.10, m=   rf, time= 15s, acc=0.91, pp=0, tc=cv-2, ans=BABAAEDBAAACBAEEABBB predictors=xyz
#p=0.10, m=  lda, time=  1s, acc=0.63, pp=0, tc=cv-2, ans=BABCCCDDAAAABAEACBBB predictors=xyz
#p=0.10, m=rpart, time=  2s, acc=0.34, pp=0, tc=cv-2, ans=AAAAAAAAAAAAAAAAEAAA predictors=xyz
#p=0.10, m=treebag, time= 13s, acc=0.88, pp=0, tc=cv-2, ans=BABAABDDAAACBAEEAABB predictors=xyz

#p=0.10, m=  gbm, time=  7s, acc=0.96, pp=0, tc=cv-2, ans=BABAAEDDAABCBAEEABBB predictors=-xyz
#p=0.10, m=   rf, time=  9s, acc=0.97, pp=0, tc=cv-2, ans=BABAAEDBAABCBAEEABBB predictors=-xyz
#p=0.10, m=  lda, time=  1s, acc=0.48, pp=0, tc=cv-2, ans=EAAAACCDACDABABBADEB predictors=-xyz
#p=0.10, m=rpart, time=  1s, acc=0.50, pp=0, tc=cv-2, ans=ACCAACCCACCCBACBACAB predictors=-xyz
#p=0.10, m=treebag, time=  7s, acc=0.96, pp=0, tc=cv-2, ans=BABAAEDBAABCBAEEABBB predictors=-xyz
```

Up to this point I was using 2-fold cross validation for speed. I wanted more in the final model,
so I kicked it up to 5-fold. As expected, build time increased. But the good news was that the 
accuracy remained high.

```{r}
#p=0.10, m=  gbm, time= 18s, acc=0.95, pp=0, tc=cv-5, ans=BABAAEDBAABCBAEEABBB predictors=-xyz
#p=0.10, m=   rf, time= 27s, acc=0.97, pp=0, tc=cv-5, ans=BABAAEDAAABCBAEEABBB predictors=-xyz
#p=0.10, m=  lda, time=  1s, acc=0.48, pp=0, tc=cv-5, ans=EAAAACCDACDABABBADEB predictors=-xyz
#p=0.10, m=rpart, time=  2s, acc=0.50, pp=0, tc=cv-5, ans=ACCAACCCACCCBACBACAB predictors=-xyz
#p=0.10, m=treebag, time= 16s, acc=0.96, pp=0, tc=cv-5, ans=BABAAEDBAABCBAEEABBB predictors=-xyz
```

I wanted to know what would happen if we just looked at a single sensor. Would that be enough to
build a model. These were built using only the dumbbell axis variables. Accuracy dropped off, so
I abandoned this idea.

```{r}
#p=0.10, m=  gbm, time= 13s, acc=0.74, pp=0, tc=cv-5, ans=CAAAAEDAAAECBABEABAB predictors=33:41
#p=0.10, m=   rf, time= 19s, acc=0.80, pp=0, tc=cv-5, ans=AABAAEDAAAECBAEEABAB predictors=33:41
#p=0.10, m=  lda, time=  1s, acc=0.37, pp=0, tc=cv-5, ans=EAACCAAAAAAABAAEEABB predictors=33:41
#p=0.10, m=rpart, time=  1s, acc=0.36, pp=0, tc=cv-5, ans=AAAAAAAAAAAAAAAAAAAA predictors=33:41
#p=0.10, m=treebag, time= 10s, acc=0.77, pp=0, tc=cv-5, ans=AABAAEDADAEEBAEEABAB predictors=33:41
```

Basically gbm, rf, and treebag are very close for both accuracy and speed. I choose gbm for the final model.





